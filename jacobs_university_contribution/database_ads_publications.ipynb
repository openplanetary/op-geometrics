{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ads\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import io\n",
    "import pandas as pd\n",
    "from feature_class import Feature\n",
    "from paper_class import Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# routine to read information from json file\n",
    "# creates a Feature instance with extracted data\n",
    "def feature_extract(obj):\n",
    "        if '__type__' in obj and obj['__type__'] == 'Feature':\n",
    "            return Feature(obj['name'], obj['id'], obj['polygon_coordinates'], obj['publications'])\n",
    "        return Feature(\"None\", 0, \"None\", \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# routine to parse json file and fetch definition of each feature\n",
    "def parse_json_stream(text):\n",
    "    list_idx = [m.start() for m in re.finditer('}\\n', text)]\n",
    "    list_objs = []\n",
    "    last_index = 0\n",
    "    for index in list_idx:\n",
    "        new_feature = json.loads(text[last_index:index+2], object_hook=feature_extract)\n",
    "        if (new_feature.name == \"None\"):\n",
    "            break\n",
    "        list_objs += [new_feature]\n",
    "        last_index = index+2\n",
    "    return list_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_name = \"features.json\"\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(json_name) as fin:\n",
    "    features = parse_json_stream(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalos Colles\n",
      "Abalos Mensa\n",
      "Abalos Scopuli\n",
      "Abalos Undae\n",
      "Aban\n",
      "Abus Vallis\n",
      "Achar\n"
     ]
    }
   ],
   "source": [
    "# write a json file with extended list of publications for each feature\n",
    "# publications are requested from ADS API\n",
    "# list of features is stored in features variable\n",
    "with io.open('features_extended.json', 'w', encoding='utf-8') as fout:\n",
    "    for feature in features:\n",
    "        print(feature.name)\n",
    "        # request ADS API for publications based on feature name\n",
    "        # store objects of type Article\n",
    "        papers = []\n",
    "        try:\n",
    "            papers = list(ads.SearchQuery(q=feature.name, fl=['title', 'author', 'year', 'pub', 'bibcode']))\n",
    "        except (ads.exceptions.APIResponseError, ads.exceptions.SolrResponseParseError) as e:\n",
    "            \"Error: {}\".format(e)\n",
    "            continue\n",
    "        \n",
    "        citation_str = []\n",
    "        # extract several fields from each publication\n",
    "        # whole list of fields can be found in https://github.com/adsabs/adsabs-dev-api/blob/master/search.md#fields\n",
    "        for paper in papers:\n",
    "            #if (type(paper.title).__name__ == \"NoneType\"):\n",
    "            #    p_title = \"Unknown\"\n",
    "            #else:    \n",
    "            #    p_title = paper.title[0]\n",
    "                \n",
    "            #p_author = paper.first_author\n",
    "            #p_year = str(paper.year)\n",
    "            \n",
    "            #if (type(paper.pub).__name__ == \"NoneType\"):\n",
    "            #    p_pub = \", \"\n",
    "            #else:\n",
    "            #    p_pub = \" : \" + paper.pub + \", \"\n",
    "            # combine all fields in a comprehensible string\n",
    "            p = Paper(paper.title[0], paper.author, paper.year, paper.pub, paper.bibcode)\n",
    "            citation_str.append(p)\n",
    "            #citation_str.append(p_title + \" by \" + p_author + p_pub + p_year)\n",
    "        # extend feature's list of publications \n",
    "        feature.addPublications(citation_str)\n",
    "        #write extended feature info to a new json file\n",
    "        fout.write(str(json.dumps(feature.dump(), ensure_ascii=False, indent=4))+\"\\n\")\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df = pd.DataFrame([feature.to_dict() for feature in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(df[\"publications\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
